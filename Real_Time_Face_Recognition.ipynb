{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://ibb.co/pr9Hn0Z\"><img src=\"https://i.ibb.co/yBbzVf5/Annotation-2020-08-14-014434.jpg\" alt=\"Annotation-2020-08-14-014434\" border=\"0\" width=\"1000\" height=\"800\"></a>\n",
    "\n",
    "# For $1^{st}$ time use: Download Libraries\n",
    "**Follow these steps:**\n",
    " - Open \"Anaconda Prompt\". Then run the \"pip install ...\" codes there.\n",
    " - <font color=\"blue\" face=\"Consolas\"> pip install cmake </font>\n",
    " - Install Visual Studio build tools from [here](https://visualstudio.microsoft.com/thank-you-downloading-visual-studio/?sku=Community&rel=15#).\n",
    " - In Visual Studio 2017 go to the Individual Components tab, Visual C++ Tools for Cmake, and check the checkbox under the \"Compilers, build tools and runtimes\" section. Visual Studio 2017 (1.41 GB) software will be downloaded; run the software first time after installation; then close the software.\n",
    " - <font color=\"blue\" face=\"Consolas\"> pip install dlib </font>\n",
    " - <font color=\"blue\" face=\"Consolas\"> pip install opencv-contrib-python face_recognition</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\" size = \"6\" face=\"Comic Sans MS\">Train Model with Training Dataset & Save Trained variables </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section-1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os               # This library is used to get access to your Operating System\n",
    "import numpy as np      # This library is used to manipulate & claculate with Vectors & Arrays\n",
    "import scipy.io as sio  # This library is used to save Dataset variables as MATLAB Matrix format (*.mat) & Read them again from *.mat file\n",
    "import cv2              # This library is used in this program to Recognize faces & get access to your Webcam. \n",
    "import face_recognition # This library is used to Face Image Reading & all the manipulation required to recognaize faces.\n",
    "import datetime         # This library is used to get the TimeStamp in order to store Matched faces name with Matched Date-Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section-2: Load & Read Training Dataset Images\n",
    "**Step-1: Make a list of images stored in the 'known_faces' (Training Dataset) folder.**\n",
    "\n",
    "**<font color=\"blue\" face=\"Comic Sans MS\">\n",
    "    Note: In the 'known_faces' (Training Dataset) folder, store images that are less than 3000x3000 pixels & of '.jpg format'. Otherwise, the program will crash. \n",
    "</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "\n",
    "mypath = './known_faces/'\n",
    "known_faces = []\n",
    "for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "    known_faces.extend(filenames)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can check:**\n",
    "- <font color=\"blue\" face=\"Consolas\"> print(known_faces) </font>\n",
    "\n",
    "**Step-2: Read aforementioned list of images in the 'known_faces' (Training Dataset) folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []    # Make an empty List\n",
    "\n",
    "for i in range(len(known_faces)):\n",
    "    im = face_recognition.load_image_file('./known_faces/' + known_faces[i])\n",
    "    image_list.append(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can check:**\n",
    "- <font color=\"blue\" face=\"Consolas\"> print(len(image_list)) </font>\n",
    "- <font color=\"blue\" face=\"Consolas\"> print('{} image values = {}'.format(str(i),image_list[-1]))  </font> # Last image values are shown for example.\n",
    "\n",
    "\n",
    "**Step-3: Subtract \".jpg\" portion from the \"known_faces\" list to have \"Names\" only.**\n",
    "- [Tutorial-1](https://www.geeksforgeeks.org/subtract-string-lists-in-python/) & [Tutorial-2](https://stackoverflow.com/questions/39751920/how-to-subtract-known-substring-from-larger-string/39751993): Subtract String Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(known_faces)):\n",
    "    known_faces[i] = known_faces[i].replace('.jpg','')\n",
    "    known_faces[i] = known_faces[i].replace('.JPG','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can check:**\n",
    "- <font color=\"blue\" face=\"Consolas\"> print(known_faces) </font>\n",
    "\n",
    "\n",
    "# Section-3: Training Dataset Image Face-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please wait...\n",
      "\tTraining Dataset is being loaded...\n",
      "\n",
      "\n",
      "SL no. \t\t Image_name \t Image_pixel_shape\n",
      "\n",
      "1 of 25 \t  Ahmad \t  (1650, 1632, 3)\n",
      "2 of 25 \t  Andalib \t  (2625, 2569, 3)\n",
      "3 of 25 \t  Arjya \t  (712, 709, 3)\n",
      "4 of 25 \t  Donald Trump \t  (441, 660, 3)\n",
      "5 of 25 \t  Ehsaan \t  (1152, 2048, 3)\n",
      "6 of 25 \t  Ehsan \t  (626, 335, 3)\n",
      "7 of 25 \t  Hillary Clinton \t  (1200, 1200, 3)\n",
      "8 of 25 \t  Mohi Uddin \t  (1280, 960, 3)\n",
      "9 of 25 \t  Mohi \t  (1453, 1705, 3)\n",
      "10 of 25 \t  Mohiuddin \t  (635, 311, 3)\n",
      "11 of 25 \t  Niloy \t  (3281, 1961, 3)\n",
      "12 of 25 \t  Nishat sir \t  (1092, 1092, 3)\n",
      "13 of 25 \t  Reevu \t  (3117, 1975, 3)\n",
      "14 of 25 \t  Rifat \t  (1981, 2333, 3)\n",
      "15 of 25 \t  Risat \t  (1371, 1365, 3)\n",
      "16 of 25 \t  Sadat \t  (1440, 1440, 3)\n",
      "17 of 25 \t  Sakif \t  (2401, 2161, 3)\n",
      "18 of 25 \t  Sameer \t  (2601, 2189, 3)\n",
      "19 of 25 \t  Samin \t  (3456, 5184, 3)\n",
      "20 of 25 \t  Samiul \t  (2177, 2361, 3)\n",
      "21 of 25 \t  Sazzad \t  (939, 445, 3)\n",
      "22 of 25 \t  Shafkat \t  (1673, 1925, 3)\n",
      "23 of 25 \t  Shofi \t  (281, 151, 3)\n",
      "24 of 25 \t  Turjo \t  (1549, 1949, 3)\n",
      "25 of 25 \t  Zamee \t  (923, 720, 3)\n"
     ]
    }
   ],
   "source": [
    "known_face_encoding_dictionary = []    # Make an empty List\n",
    "\n",
    "print(\"\\nPlease wait...\" + \"\\n\\tTraining Dataset is being loaded...\\n\")\n",
    "print(\"\\nSL no. \\t\\t Image_name \\t Image_pixel_shape\\n\")\n",
    "\n",
    "for i in range(len(known_faces)):\n",
    "    image_name, image = known_faces[i], image_list[i]  # Converting List string into variable\n",
    "    print(i+1, 'of', len(known_faces), '\\t ', image_name, '\\t ', image.shape)\n",
    "    face_encoded = face_recognition.face_encodings(image)[0]\n",
    "    known_face_encoding_dictionary.append(face_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can check:**\n",
    "- <font color=\"blue\" face=\"Consolas\"> print(known_face_encoding_dictionary) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section-4: Save Trained Dataset to directory so that we don't need to Train our model each time we run the Program.\n",
    "\n",
    "- **How to save & load dataset as [MATLAB Matrix (*.mat) format](https://docs.scipy.org/doc/scipy/reference/tutorial/io.html)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saved_Dataset = {\n",
    "                    'Known_Faces_Name': known_faces,\n",
    "                    'Known_Faces_Encoding_Dictionary': known_face_encoding_dictionary\n",
    "                }\n",
    "\n",
    "sio.savemat('Trained_Dataset.mat', Saved_Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional Tutorials regarding saving Dataset as different file formats**\n",
    "- [Importing and Exporting Data in Python](https://www.coursera.org/lecture/data-analysis-with-python/importing-and-exporting-data-in-python-6DOI1)\n",
    "- [Saving Text, JSON, and CSV to a File in Python](https://stackabuse.com/saving-text-json-and-csv-to-a-file-in-python/)\n",
    "- [Reading and Writing CSV Files in Python with Pandas](https://stackabuse.com/reading-and-writing-csv-files-in-python-with-pandas/)\n",
    "- [Importing and exporting CSV files in Python](https://medium.com/@kasiarachuta/importing-and-exporting-csv-files-in-python-7fa6e4d9f408)\n",
    "- [How to Export Pandas DataFrame to a CSV File](https://datatofish.com/export-dataframe-to-csv/)\n",
    "- [Saving a Pandas Dataframe as a CSV](https://www.geeksforgeeks.org/saving-a-pandas-dataframe-as-a-csv/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Completed....**\n",
    "\n",
    "**It's time to Run Face Recognition Algorithm....**\n",
    "\n",
    "**Once you've trained your model for the 1st time, you don't need to Train them again unless you update \"known_faces\" folder; you are ready to go for Section- 5, 6 & 7 directly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\" size = \"10\" face=\"Comic Sans MS\"> Recognize Faces using Trained Model </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section-5: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os               # This library is used to get access to your Operating System\n",
    "import numpy as np      # This library is used to manipulate & claculate with Vectors & Arrays\n",
    "import scipy.io as sio  # This library is used to save Dataset variables as MATLAB Matrix format (*.mat) & Read them again from *.mat file\n",
    "import cv2              # This library is used in this program to Recognize faces & get access to your Webcam. \n",
    "import face_recognition # This library is used to Face Image Reading & all the manipulation required to recognaize faces.\n",
    "import datetime         # This library is used to get the TimeStamp in order to store Matched faces name with Matched Date-Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section-6: Read Trained Dataset which was saved earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saved_Dataset = sio.loadmat('Trained_Dataset.mat')\n",
    "known_faces = Saved_Dataset['Known_Faces_Name']\n",
    "known_face_encoding_dictionary = Saved_Dataset['Known_Faces_Encoding_Dictionary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can check:**\n",
    "- <font color=\"blue\" face=\"Consolas\"> print(known_faces) </font>\n",
    "- <font color=\"blue\" face=\"Consolas\"> print('\\n\\n') </font>\n",
    "- <font color=\"blue\" face=\"Consolas\"> print(known_face_encoding_dictionary) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section-7: Webcam video capture & Face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam = cv2.VideoCapture(0)\n",
    "previous_name = {}\n",
    "\n",
    "while True:\n",
    "    ret, frame = webcam.read()  #capture frame by frame of video\n",
    "    rgb_frame = frame[:, :, ::-1]  #converting the frame from OpenCV's BGR format to the RGB format\n",
    "\n",
    "    #finds the face locations and encodings in each frame\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "    #loops through each face in the frame\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        #checks if the face is a match for known faces\n",
    "        matches = face_recognition.compare_faces(known_face_encoding_dictionary, face_encoding)\n",
    "        #if not, labelled as Unknown\n",
    "        name = 'Unknown'\n",
    "\n",
    "        # Given a list of face encodings, compare them to a known face encoding and get a euclidean distance for each comparison face. The distance tells you how similar the faces are\n",
    "        face_distances = face_recognition.face_distance(known_face_encoding_dictionary, face_encoding)\n",
    "        best_match = np.argmin(face_distances)\n",
    "\n",
    "        if matches[best_match]:\n",
    "            name = known_faces[best_match]\n",
    "            \n",
    "            # Save Attendance Record\n",
    "            if previous_name != name:\n",
    "                datetime_object = str(datetime.datetime.now())\n",
    "                Attendance = str([datetime_object, name])\n",
    "                with open('TimeStamp_MatchedFaces.txt', 'a') as txt_File:\n",
    "                    txt_File.write(Attendance)\n",
    "                previous_name = name\n",
    "                \n",
    "            \n",
    "        #draws a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (255, 0, 0), 2)\n",
    "\n",
    "        #draws a label with the name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (255, 0, 0), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX;\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    #displays the webcam video on screen\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27: # press 'ESC' to quit\n",
    "        break\n",
    "\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refference Codes\n",
    "**1. [Face Recognition with python pyimagesearch, open-cv & Deep Learning](https://www.pyimagesearch.com/2018/06/18/face-recognition-with-opencv-python-and-deep-learning/)**\n",
    "\n",
    "**2. [Gthub-1: ageitgey](https://github.com/ageitgey/face_recognition/blob/master/examples/facerec_from_webcam_faster.py)**\n",
    "\n",
    "**3. [Gthub-2: ageitgey](https://github.com/ageitgey/face_recognition)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
